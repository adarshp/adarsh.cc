@article{KC.ea:2024,
  author = {Dharma KC
            and Justin Lieffers
            and Deepsana Shahi
            and Adarsh Pyarelal
            and Clayton Morrison
            },
  title = {Neural Machine Translation for Code Generation},
  year = {2024},
  journal = {ACM Computing Surveys}
}

@article{Erikson.ea:2024,
  author = {Jessie A Erikson
      and Mary Alt
      and Adarsh Pyarelal
      and Leah Kapa
  },
  title = {Science Vocabulary and Science Achievement in Children with
           Developmental Language Disorder and typical Language Development},
  journal = "Language, Speech, and Hearing Services in Schools",
  year = {2024},
  doi="10.1044/2024_LSHSS-24-00025"
}

@inproceedings{
Zhang.ea:2024,
title={Deep Reinforcement Learning with Vector Quantized Encoding},
author={Liang Zhang and Justin Lieffers and Pavithra Shivanna and Adarsh Pyarelal},
booktitle={Workshop on Interpretable Policies in Reinforcement Learning @RLC-2024},
year={2024},
url={https://openreview.net/forum?id=OyHqrdWADY}
}


@inproceedings{Pyarelal.ea:2023,
    title={The {ToMCAT} Dataset},
    author={Adarsh Pyarelal and Eric Duong and Caleb Jones
            Shibu and Paulo Soares and Savannah Boyd and Payal
            Khosla and Valeria Pfeifer and Diheng Zhang and Eric S Andrews and
            Rick Champlin and Vincent Paul Raymond and Meghavarshini
            Krishnaswamy and Clayton Morrison and Emily Butler and Kobus
            Barnard},
    booktitle={Thirty-seventh Conference on Neural Information Processing Systems Datasets and Benchmarks Track},
    year={2023},
    url={https://openreview.net/forum?id=ZJWQfgXQb6}
}

@inproceedings{qamar-etal-2023-speaking,
    title = "Who is Speaking? Speaker-Aware Multiparty Dialogue Act Classification",
    author = "Qamar, Ayesha and
      Pyarelal, Adarsh  and
      Huang, Ruihong",
    editor = "Bouamor, Houda  and
      Pino, Juan  and
      Bali, Kalika",
    booktitle = "Findings of the Association for Computational Linguistics: EMNLP 2023",
    month = dec,
    year = "2023",
    address = "Singapore",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.findings-emnlp.678",
    doi = "10.18653/v1/2023.findings-emnlp.678",
    pages = "10122--10135",
    abstract = "Utterances do not occur in isolation in dialogues; it is essential to have the information of who the speaker of an utterance is to be able to recover the speaker{'}s intention with respect to the surrounding context. Beyond simply capturing speaker switches, identifying how speakers interact with each other in a dialogue is crucial to understanding conversational flow. This becomes increasingly important and simultaneously difficult to model when more than two interlocutors take part in a conversation. To overcome this challenge, we propose to explicitly add speaker awareness to each utterance representation. To that end, we use a graph neural network to model how each speaker is behaving within the local context of a conversation. The speaker representations learned this way are then used to update their respective utterance representations. We experiment with both multiparticipant and dyadic conversations on the MRDA and SwDA datasets and show the effectiveness of our approach."
}

@inproceedings{miah-etal-2023-hierarchical,
    title = "Hierarchical Fusion for Online Multimodal Dialog Act Classification",
    author = "Miah, Md Messal Monem  and
      Pyarelal, Adarsh  and
      Huang, Ruihong",
    editor = "Bouamor, Houda  and
      Pino, Juan  and
      Bali, Kalika",
    booktitle = "Findings of the Association for Computational Linguistics: EMNLP 2023",
    month = dec,
    year = "2023",
    address = "Singapore",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.findings-emnlp.505",
    doi = "10.18653/v1/2023.findings-emnlp.505",
    pages = "7532--7545",
    abstract = "We propose a framework for online multimodal dialog act (DA) classification based on raw audio and ASR-generated transcriptions of current and past utterances. Existing multimodal DA classification approaches are limited by ineffective audio modeling and late-stage fusion. We showcase significant improvements in multimodal DA classification by integrating modalities at a more granular level and incorporating recent advancements in large language and audio models for audio feature extraction. We further investigate the effectiveness of self-attention and cross-attention mechanisms in modeling utterances and dialogs for DA classification. We achieve a substantial increase of 3 percentage points in the F1 score relative to current state-of-the-art models on two prominent DA classification datasets, MRDA and EMOTyDA.",
}


@InProceedings{Zhang.ea:2022c,
author="Zhang, Liang
and Lieffers, Justin
and Pyarelal, Adarsh",
editor="Gurney, Nikolos
and Sukthankar, Gita",
title="Using Features at Multiple Temporal and Spatial Resolutions to Predict Human Behavior in Real Time",
booktitle="Computational Theory of Mind for Human-Machine Teams",
year="2022",
publisher={Springer, Cham},
doi="10.1007/978-3-031-21671-8_13",
volume=13775,
pages="205--219",
abstract="When performing complex tasks, humans naturally reason at multiple temporal and spatial resolutions simultaneously. We contend that for an artificially intelligent agent to effectively model human teammates, i.e., demonstrate computational theory of mind (ToM), it should do the same. In this paper, we present an approach for integrating high and low-resolution spatial and temporal information to predict human behavior in real time and evaluate it on data collected from human subjects performing simulated urban search and rescue (USAR) missions in a Minecraft-based environment. Our model composes neural networks for high and low-resolution feature extraction with a neural network for behavior prediction, with all three networks trained simultaneously. The high-resolution extractor encodes dynamically changing goals robustly by taking as input the Manhattan distance difference between the humans' Minecraft avatars and candidate goals in the environment for the latest few actions, computed from a high-resolution gridworld representation. In contrast, the low-resolution extractor encodes participants' historical behavior using a historical state matrix computed from a low-resolution graph representation. Through supervised learning, our model acquires a robust prior for human behavior prediction, and can effectively deal with long-term observations. Our experimental results demonstrate that our method significantly improves prediction accuracy compared to approaches that only use high-resolution information.",
isbn="978-3-031-21671-8"
}

@InProceedings{Pyarelal.ea:2022,
author="Pyarelal, Adarsh
and Banerjee, Aditya
and Barnard, Kobus",
editor="Gurney, Nikolos and Sukthankar, Gita",
title="Modular Procedural Generation for Voxel Maps",
booktitle="Computational Theory of Mind for Human-Machine Teams",
year="2022",
publisher={Springer, Cham},
eventtitle="AAAI-FSS 2021",
volume=13775,
pages="85--101",
doi="10.1007/978-3-031-21671-8_6",
abstract="Task environments developed in Minecraft are becoming increasingly popular for artificial intelligence (AI) research. However, most of these are currently constructed manually, thus failing to take advantage of procedural content generation (PCG), a capability unique to virtual task environments. In this paper, we present mcg, an open-source library to facilitate implementing PCG algorithms for voxel-based environments such as Minecraft. The library is designed with human-machine teaming research in mind, and thus takes a `top-down' approach to generation, simultaneously generating low and high level machine-readable representations that are suitable for empirical research. These can be consumed by downstream AI applications that consider human spatial cognition. The benefits of this approach include rapid, scalable, and efficient development of virtual environments, the ability to control the statistics of the environment at a semantic level, and the ability to generate novel environments in response to player actions in real time.",
isbn="978-3-031-21671-8"
}


@inproceedings{Kling:2022jcd,
    author = "Kling, Felix and Li, Honglei and Li, Shuailong and Pyarelal, Adarsh and Song, Huayang and Su, Shufang and Su, Wei",
    title = "{Exotic Higgs Decays in the Type-II 2HDMs at Current and Future pp Colliders}",
    booktitle = "{2022 Snowmass Summer Study}",
    url = {https://arxiv.org/abs/2211.09001},
    eprint = "2205.12198",
    archivePrefix = "arXiv",
    primaryClass = "hep-ph",
    reportNumber = "DESY-22-090, KIAS--P22039",
    month = 5,
    year = "2022"
}

@inproceedings{alexeeva-etal-2020-mathalign,
    title = "{M}ath{A}lign: Linking Formula Identifiers to their Contextual Natural Language Descriptions",
    author = "Alexeeva, Maria  and
      Sharp, Rebecca  and
      Valenzuela-Esc{\'a}rcega, Marco A.  and
      Kadowaki, Jennifer  and
      Pyarelal, Adarsh  and
      Morrison, Clayton",
    booktitle = "Proceedings of The 12th Language Resources and Evaluation Conference",
    month = 5,
    year = "2020",
    address = "Marseille, France",
    publisher = "European Language Resources Association",
    url = "https://www.aclweb.org/anthology/2020.lrec-1.269",
    pages = "2204--2212",
    abstract = "Extending machine reading approaches to extract mathematical
    concepts and their descriptions is useful for a variety of tasks, ranging
    from mathematical information retrieval to increasing accessibility of
    scientific documents for the visually impaired. This entails segmenting
    mathematical formulae into identifiers and linking them to their natural
    language descriptions. We propose a rule-based approach for this task,
    which extracts LaTeX representations of formula identifiers and links them
    to their in-text descriptions, given only the original PDF and the location
    of the formula of interest. We also present a novel evaluation dataset for
    this task, as well as the tool used to create it.",
    language = "English",
    ISBN = "979-10-95546-34-4",
}

@article{Pyarelal:2020higgsino,
  author = "Pyarelal, Adarsh and Su, Shufang",
  title = "Higgs Assisted Razor Search for Higgsinos at a 100 TeV $pp$ Collider",
  journal = "Science China Physics, Mechanics \& Astronomy",
  url = "http://engine.scichina.com/doi/10.1007/s11433-019-1517-5",
  doi = {10.1007/s11433-019-1517-5},
  month=1,
  eprinttype   = {arxiv},
  eprint       = {1907.11326},
  eprintclass  = {hep-ph},
  year = "2020",
}

@inproceedings{sharp-etal-2019-eidos,
    title = "Eidos, {INDRA}, {\&} Delphi: From Free Text to Executable Causal Models",
    author = "Sharp, Rebecca  and
      Pyarelal, Adarsh  and
      Gyori, Benjamin  and
      Alcock, Keith  and
      Laparra, Egoitz  and
      Valenzuela-Esc{\'a}rcega, Marco A.  and
      Nagesh, Ajay  and
      Yadav, Vikas  and
      Bachman, John  and
      Tang, Zheng  and
      Lent, Heather  and
      Luo, Fan  and
      Paul, Mithun  and
      Bethard, Steven  and
      Barnard, Kobus  and
      Morrison, Clayton  and
      Surdeanu, Mihai",
    editor = "Ammar, Waleed  and
      Louis, Annie  and
      Mostafazadeh, Nasrin",
    booktitle = "Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics (Demonstrations)",
    month = jun,
    year = "2019",
    address = "Minneapolis, Minnesota",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/N19-4008",
    doi = "10.18653/v1/N19-4008",
    pages = "42--47",
    abstract = "Building causal models of complicated phenomena such as food insecurity is currently a slow and labor-intensive manual process. In this paper, we introduce an approach that builds executable probabilistic models from raw, free text. The proposed approach is implemented through three systems: Eidos, INDRA, and Delphi. Eidos is an open-domain machine reading system designed to extract causal relations from natural language. It is rule-based, allowing for rapid domain transfer, customizability, and interpretability. INDRA aggregates multiple sources of causal information and performs assembly to create a coherent knowledge base and assess its reliability. This assembled knowledge serves as the starting point for modeling. Delphi is a modeling framework that assembles quantified causal fragments and their contexts into executable probabilistic models that respect the semantics of the original text, and can be used to support decision making.",
}

@Article{Kling2019,
  author="Kling, Felix
          and Li, Honglei
          and Pyarelal, Adarsh
          and Song, Huayang
          and Su, Shufang",
  title="Exotic Higgs decays in Type-II 2HDMs at the LHC and future 100 TeV
         hadron colliders",
  journal="Journal of High Energy Physics",
  year="2019",
  month=6,
  day="10",
  volume="2019",
  number="6",
  pages="31",
  abstract="The exotic decay modes of non-Standard Model (SM) Higgses in models
  with extended Higgs sectors have the potential to serve as powerful search
  channels to explore the space of Two-Higgs Doublet Models (2HDMs). Once
  kinematically allowed, heavy Higgses could decay into pairs of light non-SM
  Higgses, or a non-SM Higgs and a SM gauge boson, with branching fractions that
  quickly dominate those of the conventional decay modes to SM particles. In this
  study, we focus on the prospects of probing Type-II 2HDMs at the LHC and a
  future 100 TeV pp collider via exotic decay channels. We study the three
  prominent exotic decay channels: A {\textrightarrow} HZ, A {\textrightarrow}
  H{\textpm}W∓ and H{\textpm} {\textrightarrow} HW{\textpm}, and find that a
  100-TeV pp collider can probe most of the region of the Type-II 2HDM parameter
  space that survives current theoretical and experimental constraints with
  sizable exotic decay branching fraction through these channels, making them
  complementary to the conventional decay channels for heavy non-SM Higgses.",
  issn="1029-8479",
  doi="10.1007/JHEP06(2019)031",
  url="https://doi.org/10.1007/JHEP06(2019)031",
}

@article{Kling:2015uba,
      author         = "Kling, Felix and Pyarelal, Adarsh and Su, Shufang",
      title          = "{Light Charged Higgs Bosons to AW/HW via Top Decay}",
      journal        = "Journal of High Energy Physics",
      month          = 11,
      volume         = "11",
      year           = "2015",
      pages          = "051",
      doi            = "10.1007/JHEP11(2015)051",
      url="http://link.springer.com/article/10.1007\%2FJHEP11\%282015\%29051"
}

@inproceedings{Morrison:2020,
  author = "Clayton T. Morrison and Paul D. Hein and Adarsh Pyarelal and Gerrit
            Hoogenboom and Cheryl Porter",
  title = "Tools to Support Computational Crop Model Analysis and Comparison",
  booktitle = "Proceedings of the Second International Crop Modelling Symposium (iCROPM2020)",
  month = 2,
  year = "2020",
  address = "Montpellier, France"
}


@inproceedings{Erikson_Pyarelal:2022b,
  author = "Jessie Alise Erikson and Mary Alt and Adarsh Pyarelal",
  title = "Science Vocabulary and Language Skills Predict Science Achievement in Students with and without DLD",
  booktitle = "American Speech \& Hearing Association (ASHA) Convention",
  month = 11,
  year = "2022",
  address = "New Orleans, Louisiana, USA"
}

@inproceedings{Erikson_Pyarelal:2022a,
  author = "Jessie Alise Erikson and Mary Alt and Adarsh Pyarelal",
  title = "Science vocabulary knowledge and science achievement for children with and without developmental language disorder",
  booktitle = "Symposium on Research in Child Language Disorders (SRCLD)",
  month = 6,
  year = "2022",
  address = "University of Wisconsin-Madison"
}

@inproceedings{Schoelen:2021,
  author = "Siena Schoelen and Adarsh Pyarelal and Jessie {Erikson Pyarelal} and Mary Alt",
  title = "Sci-Vocab: An open-source web app for studying scientific vocabulary",
  booktitle = "Annual University of Arizona Undergraduate Biology Research Program (UBRP) Conference",
  month = 1,
  year = "2021",
  address = "Tucson, Arizona, USA"
}

@inproceedings{Erikson_Pyarelal:2021,
  author = "Jessie {Erikson Pyarelal} and Siena Schoelen and Mary Alt and Adarsh Pyarelal",
  title = "A Low-Language Alternative for Measuring Academic Science Vocabulary Depth",
  booktitle = "Symposium on Research in Child Language Disorders (SRCLD)",
  month = 6,
  year = "2021",
  address = "University of Wisconsin-Madison"
}

@inproceedings{Pyarelal.ea:2019,
  author       = {Adarsh Pyarelal and Marco Antonio Valenzuela-Esc{\'a}rcega
                  and Rebecca Sharp and Paul D. Hein and Jon Stephens and
                  Pratik Bhandari and HeuiChan Lim and Saumya Debray and
                  Clayton T. Morrison},
  title        = {AutoMATES: Automated Model Assembly from Text, Equations, and Software},
  langid       = {english},
  booktitle    = {Modeling the World's Systems},
  url = {https://arxiv.org/abs/2001.07295},
  langidopts   = {variant=american},
  eprinttype   = {arxiv},
  eprint       = {2001.07295},
  eprintclass  = {cs.AI},
  month        = 5,
  year         = 2019,
  address      = "Washington, DC"
}

@inproceedings{Pyarelal.ea:2019b,
    title = "Interpreting Causal Expressions with Gradable Adjectives to Assemble Dynamics Models",
    author = "Adarsh Pyarelal
      and Rebecca Sharp
      and Clayton Morrison
      and Kobus Barnard",
    booktitle = "Modeling the World's Systems",
    month = 5,
    year = "2019",
    address = "Washington, DC"
}

@inproceedings{Sharp.ea:2019b,
    title = "Eidos, {INDRA}, {\&} Delphi: From Free Text to Executable Causal Models",
    author = "Sharp, Rebecca  and
      Pyarelal, Adarsh  and
      Gyori, Benjamin  and
      Alcock, Keith  and
      Laparra, Egoitz  and
      Valenzuela-Esc{\'a}rcega, Marco A.  and
      Nagesh, Ajay  and
      Yadav, Vikas  and
      Bachman, John  and
      Tang, Zheng  and
      Lent, Heather  and
      Luo, Fan  and
      Paul, Mithun  and
      Bethard, Steven  and
      Barnard, Kobus  and
      Morrison, Clayton  and
      Surdeanu, Mihai",
    booktitle = "Modeling the World's Systems",
    month = 5,
    year = "2019",
    address = "Washington, DC"
}

@inproceedings{Soares.ea:2021,
   author = {Paulo Soares and Adarsh Pyarelal and Kobus Barnard},
   title = {Probabilistic Modeling of Human Teams to Infer False Beliefs},
   booktitle = {AAAI Fall Symposium on Computational Theory of Mind for Human-Machine Teams},
   month = {nov},
   year = {2021},
   url = "https://drive.google.com/file/d/1_ncab_ZXAagVyWVwvTuTmbLqRXnfNFcB/view"
}


@inproceedings{Zhang.ea:2021,
   author = {Liang Zhang and Justin Lieffers and Adarsh Pyarelal},
   title = {Using Features at Multiple Temporal and Spatial Resolutions to Predict Human Behavior in Real Time},
   booktitle = {AAAI Fall Symposium on Computational Theory of Mind for Human-Machine Teams},
   month = {nov},
   year = {2021},
   eprinttype   = {arxiv},
   eprint       = {2211.06721},
   primaryClass = "cs.AI",
}

@inproceedings{Pyarelal.ea:2021,
  author       = {Adarsh Pyarelal and Aditya Banerjee and Kobus Barnard},
  title        = {Modular Procedural Generation for Voxel Maps},
  langid       = {english},
  langidopts   = {variant=american},
  booktitle = {AAAI Fall Symposium on Computational Theory of Mind for Human-Machine Teams},
  month = {nov},
  year = {2021},
  eprinttype   = {arxiv},
  eprint       = {2104.08890},
  eprintclass  = {cs.AI},
}

@inproceedings{nitschke-etal-2022-rule,
    title = "Rule Based Event Extraction for Artificial Social Intelligence",
    author = "Nitschke, Remo  and
      Wang, Yuwei  and
      Chen, Chen  and
      Pyarelal, Adarsh  and
      Sharp, Rebecca",
    booktitle = "Proceedings of the First Workshop on Pattern-based Approaches to NLP in the Age of Deep Learning",
    month = oct,
    year = "2022",
    address = "Gyeongju, Republic of Korea",
    publisher = "International Conference on Computational Linguistics",
    url = "https://aclanthology.org/2022.pandl-1.9",
    pages = "71--84",
    abstract = "Natural language (as opposed to structured communication modes
        such as Morse code) is by far the most common mode of communication
        between humans, and can thus provide significant insight into both
        individual mental states and interpersonal dynamics. As part of
        DARPA{'}s Artificial Social Intelligence for Successful Teams (ASIST)
        program, we are developing an AI agent team member that constructs and
        maintains models of their human teammates and provides appropriate
        task-relevant advice to improve team processes and mission performance.
        One of the key components of this agent is a module that uses a
        rule-based approach to extract task-relevant events from natural
        language utterances in real time, and publish them for consumption by
        downstream components. In this case study, we evaluate the performance
        of our rule-based event extraction system on a recently conducted ASIST
        experiment consisting of a simulated urban search and rescue mission in
        Minecraft. We compare the performance of our approach with that of a
        zero-shot neural classifier, and find that our approach outperforms the
        classifier for all event types, even when the classifier is used in an
        oracle setting where it knows how many events should be extracted from
        each utterance.",
}

@eprint{Basavaraj.ea:2022,
  doi = {10.48550/ARXIV.2211.09001},
  url = {https://arxiv.org/abs/2211.09001},
  author = {Basavaraj, Chinmai and Pyarelal, Adarsh and Carter, Evan},
  title = {Multi-Timescale Modeling of Human Behavior},
  publisher = {arXiv},
  year = {2022},
  primaryClass = "cs.LG",
  eprinttype   = {arxiv},
  eprint       = {2211.09001},
  copyright = {Creative Commons Attribution Share Alike 4.0 International},
}


@misc{Zhang.ea:2022a,
  doi = {10.48550/ARXIV.2211.06733},
  author = {Zhang, Liang and Lieffers, Justin and Pyarelal, Adarsh},
  keywords = {Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Deep Reinforcement Learning with Vector Quantized Encoding},
  publisher = {arXiv},
  year = {2022},
  primaryClass = "cs.LG",
  eprinttype   = {arxiv},
  eprint       = {2211.06733},
}

@inproceedings{Zhang.ea:2025,
    title = "Enhancing Interpretability in Deep Reinforcement Learning through Semantic Clustering",
    author = "Liang Zhang
        and Justin Lieffers
        and Adarsh Pyarelal",
    year = 2025,
    booktitle={The Thirty-ninth Annual Conference on Neural Information Processing Systems (NeurIPS 2025)},
    url={https://openreview.net/forum?id=YTk1kATzOd}
}

@inproceedings{Pyarelal.ea:2025,
    title = "{M}ulti{CAT}: Multimodal Communication Annotations for Teams",
    author = "Pyarelal, Adarsh  and
      Culnan, John M  and
      Qamar, Ayesha  and
      Krishnaswamy, Meghavarshini  and
      Wang, Yuwei  and
      Jeong, Cheonkam  and
      Chen, Chen  and
      Miah, Md Messal Monem  and
      Hormozi, Shahriar  and
      Tong, Jonathan  and
      Huang, Ruihong",
    editor = "Chiruzzo, Luis  and
      Ritter, Alan  and
      Wang, Lu",
    booktitle = "Findings of the Association for Computational Linguistics: NAACL 2025",
    month = apr,
    year = "2025",
    address = "Albuquerque, New Mexico",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2025.findings-naacl.61/",
    pages = "1077--1111",
    ISBN = "979-8-89176-195-7",
    abstract = "Successful teamwork requires team members to understand each other and communicate effectively, managing multiple linguistic and paralinguistic tasks at once. Because of the potential for interrelatedness of these tasks, it is important to have the ability to make multiple types of predictions on the same dataset. Here, we introduce Multimodal Communication Annotations for Teams (MultiCAT), a speech- and text-based dataset consisting of audio recordings, automated and hand-corrected transcriptions. MultiCAT builds upon data from teams working collaboratively to save victims in a simulated search and rescue mission, and consists of annotations and benchmark results for the following tasks: (1) dialog act classification, (2) adjacency pair detection, (3) sentiment and emotion recognition, (4) closed-loop communication detection, and (5) vocal (phonetic) entrainment detection. We also present exploratory analyses on the relationship between our annotations and team outcomes. We posit that additional work on these tasks and their intersection will further improve understanding of team communication and its relation to team performance. Code {\&} data: https://doi.org/10.5281/zenodo.14834835"
}



@inproceedings{Noriega.ea:2024,
    title = "When and Where Did it Happen? An Encoder-Decoder Model to Identify Scenario Context",
    author = "Noriega-Atala, Enrique  and
      Vacareanu, Robert  and
      Ashton, Salena Torres  and
      Pyarelal, Adarsh  and
      Morrison, Clayton T  and
      Surdeanu, Mihai",
    editor = "Al-Onaizan, Yaser  and
      Bansal, Mohit  and
      Chen, Yun-Nung",
    booktitle = "Findings of the Association for Computational Linguistics: EMNLP 2024",
    month = nov,
    year = "2024",
    address = "Miami, Florida, USA",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.findings-emnlp.219/",
    doi = "10.18653/v1/2024.findings-emnlp.219",
    pages = "3821--3829",
    abstract = "We introduce a neural architecture finetuned for the task of scenario context generation: The relevant location and time of an event or entity mentioned in text. Contextualizing information extraction helps to scope the validity of automated finings when aggregating them as knowledge graphs. Our approach uses a high-quality curated dataset of time and location annotations in a corpus of epidemiology papers to train an encoder-decoder architecture. We also explored the use of data augmentation techniques during training. Our findings suggest that a relatively small fine-tuned encoder-decoder model performs better than out-of-the-box LLMs and semantic role labeling parsers to accurate predict the relevant scenario information of a particular entity or event."
}

@inproceedings{Lieffers.ea:2025,
  author = {Justin Lieffers
      and Deepsana Shahi
      and Clayton T Morrison
      and Adarsh Pyarelal
  },
  title = {Diversifying Synthetic Data for Data-Scarce Domains},
  booktitle = "JMLR",
  year = {2025},
}

@inproceedings{Liu.ea:2025,
    title = "Variable Extraction for Model Recovery in Scientific Literature",
    author = "Liu, Chunwei  and
      Noriega-Atala, Enrique  and
      Pyarelal, Adarsh  and
      Morrison, Clayton T  and
      Cafarella, Mike",
    editor = "Jansen, Peter  and
      Dalvi Mishra, Bhavana  and
      Trivedi, Harsh  and
      Prasad Majumder, Bodhisattwa  and
      Hope, Tom  and
      Khot, Tushar  and
      Downey, Doug  and
      Horvitz, Eric",
    booktitle = "Proceedings of the 1st Workshop on AI and Scientific Discovery: Directions and Opportunities",
    month = may,
    year = "2025",
    address = "Albuquerque, New Mexico, USA",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2025.aisd-main.1/",
    doi = "10.18653/v1/2025.aisd-main.1",
    pages = "1--12",
    ISBN = "979-8-89176-224-4",
    abstract = "Due to the increasing productivity in the scientific community, it is difficult to keep up with the literature without the assistance of AI methods. This paper evaluates various methods for extracting mathematical model variables from epidemiological studies, such as `infection rate ($\alpha$),'' `recovery rate ($\gamma$),'' and `mortality rate ($\mu$).'' Variable extraction appears to be a basic task, but plays a pivotal role in recovering models from scientific literature. Once extracted, we can use these variables for automatic mathematical modeling, simulation, and replication of published results. We also introduce a benchmark dataset comprising manually-annotated variable descriptions and variable values extracted from scientific papers. Our analysis shows that LLM-based solutions perform the best. Despite the incremental benefits of combining rule-based extraction outputs with LLMs, the leap in performance attributed to the transfer-learning and instruction-tuning capabilities of LLMs themselves is far more significant. This investigation demonstrates the potential of LLMs to enhance automatic comprehension of scientific artifacts and for automatic model recovery and simulation."
}

@inproceedings{Soares.ea:2024,
title={Probabilistic Modeling of Interpersonal Coordination Processes},
author = {Paulo Soares and Adarsh Pyarelal and Meghavarshini
             Krishnaswamy and Emily Butler and Kobus Barnard},
booktitle={Forty-first International Conference on Machine Learning (ICML 2024)},
year={2024},
url={https://openreview.net/forum?id=4zOZ0yKhm6}
}
